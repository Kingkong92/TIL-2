# Day12 미니프로젝트

# 다른 과정에서 만든 프로젝트

1. 영상 제작자를 위한 컨텐츠 추천 서비스(공모전 우수상)
   - 소비자를 위한 추천 서비스는  많지만 제작자를 위한 것은 없다.
   - 머신러닝을 사용한 최적의 스토리 예측
   - 선형회귀모델을 사용한 개봉 예정작의 평점 예측
   - Keras신경망을 사용한 개봉 예정작의 순이익 예측
     - 인공지능의 꽃은 CNN이고, 신경망의 꽃은 RNN(시계열 데이터 분석 방법)
     - 자연어처리 : 문장이해 보다 문장 생성이 어렵다.
     - Bayes filter를 이용하여야 더 좋은 결과를 만들어 낼 수 있다.
2. 딥러닝을 활용한 얼굴인식 출석체크
   - open CV를 활용한 이미지 회전, 이동을 통해서 훈련 데이터 증식
   - CNN, GoogLeNet
       - image net 대회 : 훈련데이터로 훈련하여 사진이 주어졌을 때 분류하는 대회
       - GoogLeNet : imagenet 대회 수상한 방식
3. 사용자가 그린 그림을 정확한 사진으로 바꾸기
   - 태극기와 토끼 등 여러 그림을 다양한 방법으로 그려서 훈련데이터 생성
   - 이를 이용하여 훈련 후 변환 버튼을 통하여 실제 사진으로 바꿔줌
4. Author By AI
   - 인공지능이 그린 그림들에서 아이디어를 얻어 히트곡을 데이터로 작사 진행
   - 모델 설계 : AI와 창작 RNN, LSTM Parameter 설정
5. 역세권 청년주택 최적 입지(공모전 우수상)
   - 입지와 관련된 지자체 반발로 인해 실 진행률이 낮음(객관적 자료 제시를 통해 설득)
   - RNN 기반
   - 부동산, 범죄, 교통, 편의시설 데이터를 기반으로 훈련
6. 서울시 국공립 어린이집 최적 입지 찾기(공모전 우수상)
   - 잠재 이용 아동 인구와 접근성 취약 지역을 분석하여 보다 시급한 지역의 유휴시설을 활용하여 국공립 어린이집을 확충할 필요가 있음
   - 직접 얻을 수 있는 관련데이터와 직접 얻을 수 없는 경우 다른 데이터를 이용하여 추정하여 사용

# 미니프로젝트

- 정규식 적용 (특정 키워드만 추출, 숫자만 추출 등의 작업)

1. 네이버/다음(기간:2019) -> 날씨 -> 텍스트 추출 / 수집
- => 단어 빈도수, 워드클라우드
2. 신문사/방송사 -> '특정단어' 기사 추출 / 수집
   - 경제 -> 환율 단어 검색 -> 기사 스크랩
   - 카테고리별 데이터 추출
   - 특정 월/년/분기 별로 추출
   - 전체 기간 추출
3. 네이버/다음 영화 댓글/평점 추출 / 수집
4. 커피자판기(키오스크) 업그레이드

- 이 중 하나 골라서 5시까지 만들기

- requests 모듈 : 딕셔너리(결과값)
- urllib모둘 : 바이너리



## 네이버/다음 영화 댓글/평점 추출 / 수집

```python
# 네이버 영화 댓글/평점 추출/수집
import re
from bs4 import BeautifulSoup
import requests
import urllib.request as req
from selenium import webdriver
import math

movie_name = []
point = []
comment = []

base_url = "https://movie.naver.com/movie/point/af/list.nhn"
page_url = "?&page="
base_response = requests.get(base_url)
base_soup = BeautifulSoup(base_response.text, "html.parser")
last_page_num = 1000

page_links = []
for page in range(1, last_page_num + 1) :
    page_links.append(base_url + page_url + str(page))

for link in page_links :
    page_response = requests.get(link)
    page_soup = BeautifulSoup(page_response.text, "html.parser")
    # 영화제목
    for tag in page_soup.select("td.title a.movie") :
        movie_name.append(tag.text)
    # 평점
    for tag in page_soup.select("td.title div.list_netizen_score em") :
        point.append(tag.text)
    # 댓글
    p = re.compile("점 중[0-9]{1,2}\n\n(.+?) \n\t\t\t\n", re.DOTALL)
    for tag in page_soup.select("td.title") :
        try : # 댓글없이 평점만 입력한 경우 None 처리
            comment.append(p.findall(tag.text)[0])
        except IndexError :
            comment.append("None")

with open('movie_point_comment.txt', encoding='utf-8', mode='w') as f :
    f.write("MOVIE/POINT/COMMENT\n")
    for i in range(len(movie_name)) :
        f.write(movie_name[i])
        f.write("\n")
        f.write(point[i])
        f.write("\n")
        f.write(comment[i])
        f.write("\n")
        f.write("\n")
```

